# SubmitJob API - Frontend Reference

This document describes all fields available in the `SubmitJobRequest` API for submitting batch jobs to Jennah. Use this as a reference when building frontend forms, API clients, or workflows.

---

## Table of Contents

1. [SubmitJobRequest Fields](#submitjobrequest-fields)
2. [Resource Presets](#resource-presets)
3. [Validation Rules](#validation-rules)
4. [Common Examples](#common-examples)
5. [Response Format](#response-format)
6. [Error Handling](#error-handling)

---

## SubmitJobRequest Fields

### **Core Fields (Required)**

#### `image_uri` (string) - **REQUIRED**

- **Type**: String (URL)
- **Description**: The container image URI to run
- **Format**: Full container image path with optional tag
- **Examples**:
  - `gcr.io/my-project/my-app:latest`
  - `docker.io/library/python:3.11`
  - `us-docker.pkg.dev/my-project/my-repo/my-image:v1.2.3`
- **Validation**:
  - Must not be empty
  - Should be a valid container image URI
  - Must be accessible by the GCP service account
- **Backend mapping**: Directly mapped to GCP Batch `batchpb.Runnable_Container.ImageUri`

---

### **Job Naming & Identification**

#### `name` (string) - **OPTIONAL**

- **Type**: String
- **Default**: None (auto-generated UUID-based ID used instead)
- **Description**: Human-readable job name for your reference
- **Examples**:
  - `"data-pipeline-daily-2026-02-26"`
  - `"model-training-gpu-run"`
  - `"batch-import-v2"`
- **Constraints**:
  - If provided, used to generate provider-compatible job ID
  - Should be descriptive but concise
  - Alphanumeric, hyphens, underscores recommended
- **Backend mapping**: Used in provider job ID generation (`jennah-{name}` or `jennah-{uuid[:8]}`)

#### `job_id` (string) - **OPTIONAL (Gateway-generated)**

- **Type**: String (UUID)
- **Default**: Generated by gateway if empty
- **Description**: Internal canonical job ID (rarely set by frontend)
- **Notes**: Typically generated server-side; only set if resubmitting with idempotency

---

### **Compute Configuration**

#### `resource_profile` (string) - **OPTIONAL**

- **Type**: Enum (string)
- **Default**: `"medium"`
- **Description**: Named preset for CPU, memory, and timeout
- **Valid values**:
  - `"small"` - 2 vCPU, 2 GiB memory, 1800s timeout
  - `"medium"` - 4 vCPU, 4 GiB memory, 3600s timeout
  - `"large"` - 8 vCPU, 8 GiB memory, 7200s timeout
  - `"xlarge"` - 16 vCPU, 16 GiB memory, 14400s timeout
- **Backend mapping**: Resolved to CPU/memory values before submission to GCP
- **Notes**: Can be overridden with `resource_override` for fine-grained control

#### `resource_override` (ResourceOverride) - **OPTIONAL**

- **Type**: Nested object
- **Description**: Override specific compute resources from the preset
- **Zero-values**: Fields set to 0 fall back to preset values
- **Subfields**:
  - `cpu_millis` (int64): CPU in milli-cores (1000 = 1 vCPU)
    - Example: `2000` for 2 vCPU, `500` for 0.5 vCPU
    - Set to `0` to use preset value
  - `memory_mib` (int64): Memory in mebibytes (1 GiB = 1024 MiB)
    - Example: `4096` for 4 GiB, `512` for 512 MiB
    - Set to `0` to use preset value
  - `max_run_duration_seconds` (int64): Job timeout in seconds
    - Example: `3600` for 1 hour, `86400` for 24 hours
    - Set to `0` to use preset value

**Example: Override memory only, keep preset CPU & timeout**

```json
{
  "resource_profile": "medium",
  "resource_override": {
    "memory_mib": 8192 // 8 GiB instead of 4 GiB
    // cpu_millis: 0 (use preset 4000)
    // max_run_duration_seconds: 0 (use preset 3600)
  }
}
```

#### `machine_type` (string) - **OPTIONAL**

- **Type**: String (GCP Compute Engine machine type)
- **Default**: Auto-selected based on resource_profile
- **Description**: Specific GCP machine type to use
- **Common values**:
  - `"e2-standard-4"` - 4 vCPU, 16 GiB (cost-optimized)
  - `"n1-standard-4"` - 4 vCPU, 15 GiB (general purpose)
  - `"n1-standard-16"` - 16 vCPU, 60 GiB (high-compute)
  - `"e2-highmem-4"` - 4 vCPU, 32 GiB (memory-intensive)
- **Validation**:
  - Must be a valid GCP machine type
  - Query [GCP Machine Types](https://cloud.google.com/compute/docs/machine-resource)
  - Must be available in the job's region (asia-northeast1)
- **Backend mapping**: Maps to GCP Batch `AllocationPolicy_InstancePolicy.MachineType`

#### `boot_disk_size_gb` (int64) - **OPTIONAL**

- **Type**: Integer
- **Default**: `50` (50 GB)
- **Description**: Boot disk size in gigabytes
- **Validation**:
  - Minimum: `10` GB
  - Maximum: `65536` GB (~64 TB)
  - Must be an integer
- **Examples**:
  - `100` for 100 GB boot disk (suitable for large datasets loaded at startup)
  - `30` for 30 GB boot disk (suitable for light workloads)
- **Backend mapping**: Converted to MiB for GCP Batch `AllocationPolicy_Disk`

#### `use_spot_vms` (bool) - **OPTIONAL**

- **Type**: Boolean
- **Default**: `false`
- **Description**: Enable Spot VMs for cost savings
- **Trade-offs**:
  - **Pros**: 60-90% cheaper than standard VMs
  - **Cons**: Can be preempted at any time; lower SLA
- **Best for**: Batch jobs, fault-tolerant workloads, non-critical tasks
- **Not recommended for**: Long-running interactive jobs, distributed training without checkpointing
- **Backend mapping**: Maps to GCP Batch `AllocationPolicy_ProvisioningModel.SPOT`

#### `service_account` (string) - **OPTIONAL**

- **Type**: String (email address)
- **Default**: Default Compute Engine service account
- **Description**: Custom service account for running tasks
- **Format**: Must be a valid GCP service account email (e.g., `my-sa@my-project.iam.gserviceaccount.com`)
- **Use cases**:
  - Fine-grained IAM permissions (least privilege)
  - Access to specific GCP resources (GCS buckets, databases)
  - Cross-project access
- **Validation**:
  - Must be a valid service account in the project
  - Must have necessary IAM roles for job execution
  - Batch job must have right to impersonate the account
- **Backend mapping**: Set in GCP Batch `AllocationPolicy.ServiceAccount.Email`

---

### **Container Execution**

#### `commands` (repeated string) - **OPTIONAL**

- **Type**: Array of strings
- **Default**: Container's default CMD (from image)
- **Description**: Commands to execute in the container
- **Behavior**:
  - If provided, appended to or overrides container's default CMD
  - Parsed as individual command arguments (not shell parsing)
  - ENTRYPOINT is still used; commands become the new CMD
- **Examples**:
  ```json
  "commands": ["python", "train.py", "--epochs=100", "--batch-size=32"]
  // Results in: ENTRYPOINT train.py --epochs=100 --batch-size=32
  ```
  ```json
  "commands": ["bash", "-c", "echo hello && sleep 60"]
  // Shell handling: use bash -c for complex shell syntax
  ```
- **Backend mapping**: Maps to GCP Batch `Runnable_Container.Commands`

#### `env_vars` (map<string, string>) - **OPTIONAL**

- **Type**: Key-value pairs (map)
- **Default**: Inherited from container image
- **Description**: Environment variables to pass to the container
- **Examples**:
  ```json
  "env_vars": {
    "DB_HOST": "10.0.0.1",
    "DB_PORT": "5432",
    "DEBUG": "true",
    "API_KEY": "secret-value"
  }
  ```
- **Restrictions**:
  - Use Secret Manager for sensitive values in production
  - Avoid hardcoding credentials
  - Values are passed as UTF-8 strings
- **Backend mapping**: Maps to GCP Batch `Runnable.Environment.Variables`

---

## Resource Presets

Use `resource_profile` to select a preset, or combine with `resource_override` for custom values.

### Preset Details

| Profile  | vCPU | Memory | Timeout | Best For                        |
| -------- | ---- | ------ | ------- | ------------------------------- |
| `small`  | 2    | 2 GiB  | 30 min  | Light scripts, quick tests      |
| `medium` | 4    | 4 GiB  | 1 hour  | General workloads (default)     |
| `large`  | 8    | 8 GiB  | 2 hours | Data processing, model training |
| `xlarge` | 16   | 16 GiB | 4 hours | Heavy compute, large datasets   |

### Custom Resource Examples

**High-memory, moderate compute:**

```json
{
  "resource_profile": "medium",
  "resource_override": {
    "memory_mib": 12288 // 12 GiB instead of 4 GiB
  }
}
```

**Quick timeout with ample resources:**

```json
{
  "resource_profile": "large",
  "resource_override": {
    "max_run_duration_seconds": 600 // 10 minutes instead of 2 hours
  }
}
```

**Full custom specification:**

```json
{
  "resource_override": {
    "cpu_millis": 8000, // 8 vCPU
    "memory_mib": 16384, // 16 GiB
    "max_run_duration_seconds": 1800 // 30 minutes
  }
}
```

---

## Validation Rules

### Field Validation

| Field               | Required? | Validation                           | Error Code         |
| ------------------- | --------- | ------------------------------------ | ------------------ |
| `image_uri`         | YES       | Non-empty string, valid URI          | `INVALID_ARGUMENT` |
| `name`              | NO        | Max 63 chars, alphanumeric+hyphens   | `INVALID_ARGUMENT` |
| `resource_profile`  | NO        | One of: small, medium, large, xlarge | `INVALID_ARGUMENT` |
| `machine_type`      | NO        | Valid GCP machine type               | `INVALID_ARGUMENT` |
| `boot_disk_size_gb` | NO        | Integer 10-65536                     | `INVALID_ARGUMENT` |
| `use_spot_vms`      | NO        | Boolean                              | —                  |
| `service_account`   | NO        | Valid service account email          | `INVALID_ARGUMENT` |
| `commands`          | NO        | Array of strings                     | —                  |
| `env_vars`          | NO        | Map of string->string                | —                  |

### Combined Validation Rules

- **resource_override fields**: Values of 0 are skipped; non-zero values override preset
- **Timeout precedence**: Custom override > preset > GCP default (86400 seconds)
- **Memory validation**: Must be compatible with machine type
- **CPU validation**: Override must be achievable with selected/inferred machine type

---

## Common Examples

### Example 1: Simple Job (Minimal Configuration)

```json
{
  "image_uri": "gcr.io/my-project/my-app:latest"
  // Uses: medium profile, 4vCPU, 4GiB, 1hr timeout, standard VM
}
```

### Example 2: Machine Learning Training with GPU (Future: GPU Support)

```json
{
  "name": "model-training-run-1",
  "image_uri": "us-docker.pkg.dev/my-project/ml/tensorflow:latest",
  "resource_profile": "xlarge",
  "boot_disk_size_gb": 100,
  "use_spot_vms": true,
  "service_account": "ml-sa@my-project.iam.gserviceaccount.com",
  "commands": ["python", "train.py", "--batch-size=64"],
  "env_vars": {
    "CUDA_VISIBLE_DEVICES": "0",
    "TF_CPP_MIN_LOG_LEVEL": "2"
  }
}
```

### Example 3: Data Processing with Custom Resources

```json
{
  "name": "daily-data-pipeline",
  "image_uri": "gcr.io/my-project/data-processor:v2.1",
  "resource_profile": "medium",
  "resource_override": {
    "cpu_millis": 6000, // 6 vCPU (instead of 4)
    "memory_mib": 8192, // 8 GiB (instead of 4 GiB)
    "max_run_duration_seconds": 7200 // 2 hours
  },
  "commands": ["python", "pipeline.py", "--date=2026-02-26"],
  "env_vars": {
    "SOURCE_BUCKET": "gs://my-source",
    "DEST_BUCKET": "gs://my-dest",
    "LOG_LEVEL": "INFO"
  }
}
```

### Example 4: Quick Sanity Check (Cost-Optimized)

```json
{
  "name": "quick-test",
  "image_uri": "alpine:latest",
  "resource_profile": "small",
  "use_spot_vms": true,
  "commands": ["sh", "-c", "echo 'Hello World' && sleep 5"]
}
```

### Example 5: Sensitive Operations with Custom SA

```json
{
  "name": "secure-database-backup",
  "image_uri": "gcr.io/my-project/db-backup:latest",
  "service_account": "backup-sa@my-project.iam.gserviceaccount.com",
  "resource_profile": "medium",
  "env_vars": {
    "DB_CONNECTION_POOL_SIZE": "10"
    // Credentials should be mounted via IAM role, not env vars
  }
}
```

---

## Response Format

### Success Response (HTTP 200)

```json
{
  "job_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "PENDING",
  "worker_assigned": "10.100.0.15"
}
```

**Fields**:

- `job_id` (string): Canonical internal job ID for tracking
- `status` (string): Initial job status (usually `PENDING` or `SCHEDULED`)
- `worker_assigned` (string): IP address of assigned worker (for reference)

### Error Response (HTTP 4xx/5xx)

```json
{
  "error": {
    "code": "INVALID_ARGUMENT",
    "message": "image_uri is required"
  }
}
```

**Common Error Codes**:

- `INVALID_ARGUMENT`: Malformed request, missing required fields, invalid values
- `UNAUTHENTICATED`: Missing or invalid OAuth headers
- `INTERNAL`: Server-side error during job submission
- `NOT_FOUND`: Tenant not found

---

## Error Handling

### Client Responsibilities

1. **Validate before submitting**:
   - Ensure `image_uri` is non-empty and accessible
   - Verify resource overrides are reasonable
   - Validate machine type is available

2. **Handle async nature**:
   - Job submission is async; check status via `GetJob` RPC
   - Don't assume job is running immediately after response
   - Poll or use webhooks for status changes

3. **Retry transient failures**:
   - Use `job_id` as idempotency key for retries
   - Gateway automatically deduplicates identical submissions
   - Safe to retry on 5xx errors

4. **Request required headers**:
   - `Authorization: Bearer <oauth-token>` (OAuth authentication)
   - Content-Type: `application/json` or appropriate RPC format

### Common Issues & Solutions

| Error                                     | Likely Cause                      | Solution                             |
| ----------------------------------------- | --------------------------------- | ------------------------------------ |
| `INVALID_ARGUMENT: image_uri is required` | Empty image_uri                   | Provide valid container image URI    |
| `UNAUTHENTICATED`                         | Missing OAuth token               | Include valid Authorization header   |
| `INTERNAL: failed to submit batch job`    | Service account lacks permissions | Check service accountIAM roles       |
| `NOT_FOUND: tenant not found`             | Account not yet created           | Contact admin or complete onboarding |

---

## Backend Implementation Notes

- **Response format**: ConnectRPC with Protobuf serialization
- **Async execution**: Jobs run asynchronously; use `ListJobs` or `GetJob` to check status
- **Consistency**: Job data is strongly consistent via Cloud Spanner interleaved tables
- **Idempotency**: `job_id` and `RequestID` prevent duplicate submissions
- **Default region**: All jobs submitted to GCP Batch in `asia-northeast1`

---

## Related Documentation

- [GCP Compute Engine Machine Types](https://cloud.google.com/compute/docs/machine-types)
- [GCP Batch Job Configuration](https://cloud.google.com/batch/docs/create-job)
- [Container Image Best Practices](https://cloud.google.com/container-registry/docs/pushing-and-pulling)
- [OAuth Authentication](./oauth-guide.md)
- [Job Lifecycle & Status Codes](./job-lifecycle.md)
